{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading asl-signs, 40118005859 bytes compressed\n",
      "[==================================================] 40118005859 bytes downloaded\n",
      "Downloaded and uncompressed: asl-signs\n",
      "Data source import complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
    "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote, urlparse\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "CHUNK_SIZE = 40960\n",
    "DATA_SOURCE_MAPPING = 'asl-signs:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F46105%2F5087314%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240423%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240423T005456Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D05de445137be291fccc16e31846b960ae442369be6b9cf76c85d5982dc27fd1c5dc4f9cfd2ded022a600781a52b00cfee68e542bb41dfda85082af356e8d746d5841f6d5f759649c931aebe0935a25026cdc36fd4352c8e285ff10ebca3f422b5928426de9bccd0205651e6553eb9c19caab051ff92390653248efe87c53bd4d13047dddce5e7e904c60b047de829dd928ea3b7008ac7bf5453ec669f5808d85d12eb32f86a61b4ee98b056fcb8ff80bdae6039103aa2fef7289547b942d309dd9e1f14c346a0d8700e6f7988911a44dbc63ea1c8a3a52d12ef8835f3946e6732bab3c4e861835a15178d6886cabbbdcf45222311e8fe7a50bb41ffb832b29ba'\n",
    "\n",
    "KAGGLE_INPUT_PATH='kaggle/input'\n",
    "KAGGLE_WORKING_PATH='kaggle/working'\n",
    "KAGGLE_SYMLINK='kaggle'\n",
    "\n",
    "os.makedirs(KAGGLE_SYMLINK)\n",
    "os.makedirs(KAGGLE_INPUT_PATH, 0o777)\n",
    "os.makedirs(KAGGLE_WORKING_PATH, 0o777)\n",
    "\n",
    "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
    "    directory, download_url_encoded = data_source_mapping.split(':')\n",
    "    download_url = unquote(download_url_encoded)\n",
    "    filename = urlparse(download_url).path\n",
    "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
    "    try:\n",
    "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
    "            total_length = fileres.headers['content-length']\n",
    "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
    "            dl = 0\n",
    "            data = fileres.read(CHUNK_SIZE)\n",
    "            while len(data) > 0:\n",
    "                dl += len(data)\n",
    "                tfile.write(data)\n",
    "                done = int(50 * dl / int(total_length))\n",
    "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
    "                sys.stdout.flush()\n",
    "                data = fileres.read(CHUNK_SIZE)\n",
    "            if filename.endswith('.zip'):\n",
    "              with ZipFile(tfile) as zfile:\n",
    "                zfile.extractall(destination_path)\n",
    "            else:\n",
    "              with tarfile.open(tfile.name) as tarfile:\n",
    "                tarfile.extractall(destination_path)\n",
    "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
    "    except HTTPError as e:\n",
    "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
    "        continue\n",
    "    except OSError as e:\n",
    "        print(f'Failed to load {download_url} to path {destination_path}')\n",
    "        continue\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-22T19:42:17.987806Z",
     "iopub.status.busy": "2024-04-22T19:42:17.987426Z",
     "iopub.status.idle": "2024-04-22T19:42:37.396289Z",
     "shell.execute_reply": "2024-04-22T19:42:37.395467Z",
     "shell.execute_reply.started": "2024-04-22T19:42:17.987778Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T23:34:57.540902Z",
     "iopub.status.busy": "2024-04-22T23:34:57.54055Z",
     "iopub.status.idle": "2024-04-22T23:34:57.545849Z",
     "shell.execute_reply": "2024-04-22T23:34:57.544986Z",
     "shell.execute_reply.started": "2024-04-22T23:34:57.540876Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T23:35:00.499283Z",
     "iopub.status.busy": "2024-04-22T23:35:00.498868Z",
     "iopub.status.idle": "2024-04-22T23:35:00.503936Z",
     "shell.execute_reply": "2024-04-22T23:35:00.503288Z",
     "shell.execute_reply.started": "2024-04-22T23:35:00.499252Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_FRAMES=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T23:35:01.32079Z",
     "iopub.status.busy": "2024-04-22T23:35:01.320379Z",
     "iopub.status.idle": "2024-04-22T23:35:01.551961Z",
     "shell.execute_reply": "2024-04-22T23:35:01.550833Z",
     "shell.execute_reply.started": "2024-04-22T23:35:01.320762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kaggle/input/asl-signs/train_landmark_files/4718/1160474191.parquet', 'kaggle/input/asl-signs/train_landmark_files/4718/1187990396.parquet', 'kaggle/input/asl-signs/train_landmark_files/4718/2604668083.parquet', 'kaggle/input/asl-signs/train_landmark_files/4718/2266974533.parquet', 'kaggle/input/asl-signs/train_landmark_files/4718/3835935597.parquet', 'kaggle/input/asl-signs/train_landmark_files/4718/2057287272.parquet', 'kaggle/input/asl-signs/train_landmark_files/4718/3488774387.parquet', 'kaggle/input/asl-signs/train_landmark_files/4718/3210689405.parquet', 'kaggle/input/asl-signs/train_landmark_files/4718/2905175954.parquet', 'kaggle/input/asl-signs/train_landmark_files/4718/1996140943.parquet']\n"
     ]
    }
   ],
   "source": [
    "data_files = glob(\"kaggle/input/asl-signs/train_landmark_files/*/*.parquet\", recursive=True)\n",
    "print(data_files[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T23:35:08.320065Z",
     "iopub.status.busy": "2024-04-22T23:35:08.319701Z",
     "iopub.status.idle": "2024-04-22T23:35:08.34863Z",
     "shell.execute_reply": "2024-04-22T23:35:08.347764Z",
     "shell.execute_reply.started": "2024-04-22T23:35:08.320038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   frame    row_id  type  landmark_index         x         y         z\n",
      "0      9  9-face-0  face               0  0.520766  0.544308 -0.045363\n",
      "1      9  9-face-1  face               1  0.509756  0.507224 -0.059449\n",
      "2      9  9-face-2  face               2  0.512931  0.520984 -0.039289\n",
      "3      9  9-face-3  face               3  0.503155  0.481343 -0.032631\n",
      "4      9  9-face-4  face               4  0.509599  0.497557 -0.059698\n",
      "landmarks per frame 543\n",
      "face landmarks  468\n",
      "pose landmarks  33\n",
      "left hand landmarks  21\n",
      "right hand landmarks  21\n"
     ]
    }
   ],
   "source": [
    "example_pq_df = pd.read_parquet(data_files[1])\n",
    "first_frame_df = example_pq_df[example_pq_df['frame'] == example_pq_df['frame'].iloc[0]]\n",
    "first_frame_head_df = first_frame_df[first_frame_df['type'] == 'face']\n",
    "first_frame_pose_df = first_frame_df[first_frame_df['type'] == 'pose']\n",
    "first_frame_left_hand_df = first_frame_df[first_frame_df['type'] == 'left_hand']\n",
    "first_frame_right_hand_df = first_frame_df[first_frame_df['type'] == 'right_hand']\n",
    "\n",
    "print(example_pq_df.head())\n",
    "print(\"landmarks per frame\", len(first_frame_df))\n",
    "print(\"face landmarks \", len(first_frame_head_df))\n",
    "print(\"pose landmarks \", len(first_frame_pose_df))\n",
    "print(\"left hand landmarks \", len(first_frame_left_hand_df))\n",
    "print(\"right hand landmarks \", len(first_frame_right_hand_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T23:35:10.803899Z",
     "iopub.status.busy": "2024-04-22T23:35:10.803456Z",
     "iopub.status.idle": "2024-04-22T23:35:10.814826Z",
     "shell.execute_reply": "2024-04-22T23:35:10.81398Z",
     "shell.execute_reply.started": "2024-04-22T23:35:10.803866Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Methods to either upsample or downsample frames to return NUM_FRAMES freams\n",
    "'''\n",
    "def interpolate_frames(pq_df, num_frames=NUM_FRAMES):\n",
    "    current_frames = pq_df['frame'].unique()\n",
    "    needed_frames = num_frames - len(current_frames)\n",
    "    frame_interval = len(current_frames) // (needed_frames + 1)\n",
    "    for i in range(1, needed_frames + 1):\n",
    "        frame = i * frame_interval % len(pq_df['frame'].unique())\n",
    "        end_index_of_first_half = len(pq_df[pq_df['frame'] <= frame])\n",
    "        pq_df = pd.concat([pq_df[pq_df['frame'] <= frame], pq_df[pq_df['frame'] >= frame]], )\n",
    "        pq_df = pq_df.reset_index(drop=True)\n",
    "        pq_df.loc[pq_df.index >= end_index_of_first_half, 'frame'] += 1\n",
    "\n",
    "    return pq_df\n",
    "\n",
    "def extract_frames(pq_df, method='uniform' , num_frames=NUM_FRAMES):  \n",
    "    if method == 'uniform':\n",
    "        total_frames = len(pq_df['frame'].unique())\n",
    "        step_size = total_frames // num_frames\n",
    "        frame_indices_range = range(0, total_frames, step_size)\n",
    "    elif method == 'end':\n",
    "        unique_frames = pq_df['frame'].unique()\n",
    "        frame_indices_range = unique_frames[-num_frames:]\n",
    "    elif method == 'start':\n",
    "        unique_frames = pq_df['frame'].unique()\n",
    "        frame_indices_range = unique_frams[:num_frames]\n",
    "    frame_indices = list(frame_indices_range)[-num_frames:]\n",
    "    new_df = pq_df[pq_df['frame'].isin(frame_indices)]\n",
    "    for index, frame in enumerate(frame_indices):\n",
    "        new_df.loc[new_df['frame'] == frame, 'frame'] = index\n",
    "    return new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T00:29:42.901709Z",
     "iopub.status.busy": "2024-04-23T00:29:42.898235Z",
     "iopub.status.idle": "2024-04-23T00:29:43.32817Z",
     "shell.execute_reply": "2024-04-23T00:29:43.325818Z",
     "shell.execute_reply.started": "2024-04-23T00:29:42.901608Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(data_files):\n",
    "    df_lists = []\n",
    "    for i, data  in enumerate(data_files):\n",
    "        data_df = pd.read_parquet(data)\n",
    "        new_df = None\n",
    "        if(i % 100 == 0):\n",
    "            print(i)\n",
    "        if len(data_df['frame'].unique()) < NUM_FRAMES:\n",
    "            new_df = interpolate_frames(data_df)\n",
    "        elif len(data_df['frame'].unique() > NUM_FRAMES):\n",
    "            new_df = extract_frames(data_df)\n",
    "        df_lists.append(new_df)\n",
    "    return df_lists\n",
    "\n",
    "            \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m processed_data \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m(data_files)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()) \u001b[38;5;241m<\u001b[39m NUM_FRAMES:\n\u001b[0;32m----> 9\u001b[0m     new_df \u001b[38;5;241m=\u001b[39m \u001b[43minterpolate_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique() \u001b[38;5;241m>\u001b[39m NUM_FRAMES):\n\u001b[1;32m     11\u001b[0m     new_df \u001b[38;5;241m=\u001b[39m extract_frames(data_df)\n",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m, in \u001b[0;36minterpolate_frames\u001b[0;34m(pq_df, num_frames)\u001b[0m\n\u001b[1;32m     11\u001b[0m     pq_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pq_df[pq_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m frame], pq_df[pq_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m frame]], )\n\u001b[1;32m     12\u001b[0m     pq_df \u001b[38;5;241m=\u001b[39m pq_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mpq_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpq_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend_index_of_first_half\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mframe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pq_df\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/pandas/core/generic.py:12716\u001b[0m, in \u001b[0;36mNDFrame.__iadd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m  12713\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m  12714\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iadd__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m  12715\u001b[0m     \u001b[38;5;66;03m# error: Unsupported left operand type for + (\"Type[NDFrame]\")\u001b[39;00m\n\u001b[0;32m> 12716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inplace_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__add__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/pandas/core/generic.py:12686\u001b[0m, in \u001b[0;36mNDFrame._inplace_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m  12682\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mgetrefcount(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m REF_COUNT \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m  12683\u001b[0m         \u001b[38;5;66;03m# we are probably in an inplace setitem context (e.g. df['a'] += 1)\u001b[39;00m\n\u001b[1;32m  12684\u001b[0m         warn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m> 12686\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  12688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m  12689\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m  12690\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_indexed_same(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12696\u001b[0m     \u001b[38;5;66;03m# Item \"ArrayManager\" of \"Union[ArrayManager, SingleArrayManager,\u001b[39;00m\n\u001b[1;32m  12697\u001b[0m     \u001b[38;5;66;03m# BlockManager, SingleBlockManager]\" has no attribute \"setitem_inplace\"\u001b[39;00m\n\u001b[1;32m  12698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39msetitem_inplace(  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m  12699\u001b[0m         \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m), result\u001b[38;5;241m.\u001b[39m_values, warn\u001b[38;5;241m=\u001b[39mwarn\n\u001b[1;32m  12700\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/pandas/core/arraylike.py:186\u001b[0m, in \u001b[0;36mOpsMixin.__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__add__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    Get Addition of DataFrame and other, column-wise.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    moose     3.0     NaN\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/pandas/core/series.py:6126\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   6125\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[0;32m-> 6126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/pandas/core/base.py:1384\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m-> 1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/pandas/core/series.py:6222\u001b[0m, in \u001b[0;36mSeries._construct_result\u001b[0;34m(self, result, name)\u001b[0m\n\u001b[1;32m   6219\u001b[0m \u001b[38;5;66;03m# TODO: result should always be ArrayLike, but this fails for some\u001b[39;00m\n\u001b[1;32m   6220\u001b[0m \u001b[38;5;66;03m#  JSONArray tests\u001b[39;00m\n\u001b[1;32m   6221\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 6222\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   6223\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   6225\u001b[0m \u001b[38;5;66;03m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[1;32m   6226\u001b[0m \u001b[38;5;66;03m#  would set it back to self.name\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/pandas/core/series.py:593\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    590\u001b[0m         data \u001b[38;5;241m=\u001b[39m SingleArrayManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index)\n\u001b[1;32m    592\u001b[0m NDFrame\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data)\n\u001b[0;32m--> 593\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_axis(\u001b[38;5;241m0\u001b[39m, index)\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m original_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_pandas_object \u001b[38;5;129;01mand\u001b[39;00m data_dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/pandas/core/generic.py:6317\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6314\u001b[0m \u001b[38;5;66;03m# if this fails, go on to more involved attribute setting\u001b[39;00m\n\u001b[1;32m   6315\u001b[0m \u001b[38;5;66;03m# (note that this matches __getattr__, above).\u001b[39;00m\n\u001b[1;32m   6316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set:\n\u001b[0;32m-> 6317\u001b[0m     \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6318\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata:\n\u001b[1;32m   6319\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/pandas/core/series.py:782\u001b[0m, in \u001b[0;36mSeries.name\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;129m@name\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mname\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 782\u001b[0m     \u001b[43mvalidate_all_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/pandas/core/dtypes/common.py:1571\u001b[0m, in \u001b[0;36mvalidate_all_hashable\u001b[0;34m(error_name, *args)\u001b[0m\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneric\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mns\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1566\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(dtype\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is too specific of a frequency, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1567\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtry passing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(dtype\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1568\u001b[0m         )\n\u001b[0;32m-> 1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_all_hashable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, error_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;124;03m    Return None if all args are hashable, else raise a TypeError.\u001b[39;00m\n\u001b[1;32m   1574\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;124;03m    None\u001b[39;00m\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_hashable(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "processed_data = process_data(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_model(torch.nn.Module):\n",
    "    def __init__(input_dims):\n",
    "        super(NN_model, self).__init__()\n",
    "    \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(input_dims)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(output_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m120"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 5087314,
     "sourceId": 46105,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
